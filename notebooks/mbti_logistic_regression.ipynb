{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4bdae0fd",
   "metadata": {},
   "source": [
    "We use the [MBTI Kaggle Dataset](https://www.kaggle.com/datasnaek/mbti-type)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5d4e479",
   "metadata": {},
   "source": [
    "## Importing Required Libraries\n",
    "In this section, we import the key Python libraries used for data loading, preprocessing, modeling, and visualization.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "23c2a06b-305f-42f7-8019-6737311cdfd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5194eed",
   "metadata": {},
   "source": [
    "## Dataset Loading and Exploration\n",
    "\n",
    "We begin by loading the MBTI dataset and exploring its structure â€” including sample entries, class distribution, and basic statistics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "953b8ba7-ca31-4b7b-8ab4-47bf19917c43",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>type</th>\n",
       "      <th>posts</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>INFJ</td>\n",
       "      <td>'http://www.youtube.com/watch?v=qsXHcwe3krw|||...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ENTP</td>\n",
       "      <td>'I'm finding the lack of me in these posts ver...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>INTP</td>\n",
       "      <td>'Good one  _____   https://www.youtube.com/wat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>INTJ</td>\n",
       "      <td>'Dear INTP,   I enjoyed our conversation the o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ENTJ</td>\n",
       "      <td>'You're fired.|||That's another silly misconce...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   type                                              posts\n",
       "0  INFJ  'http://www.youtube.com/watch?v=qsXHcwe3krw|||...\n",
       "1  ENTP  'I'm finding the lack of me in these posts ver...\n",
       "2  INTP  'Good one  _____   https://www.youtube.com/wat...\n",
       "3  INTJ  'Dear INTP,   I enjoyed our conversation the o...\n",
       "4  ENTJ  'You're fired.|||That's another silly misconce..."
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_set = pd.read_csv('../mbti_1.csv') \n",
    "data_set.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45f33b08",
   "metadata": {},
   "source": [
    "## Data Preprocessing\n",
    "\n",
    "Here, we perform minimal text preprocessing to clean and prepare the posts for modeling.  \n",
    "The focus is not on heavy preprocessing but ensuring the text is in a usable form (e.g., lowercasing, removing URLs, punctuation, etc.)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "1d305447",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_text(df, remove_special=True):\n",
    "    texts = df['posts'].copy()\n",
    "    labels = df['type'].copy()\n",
    "\n",
    "    #Remove links \n",
    "    df[\"posts\"] = df[\"posts\"].apply(lambda x: re.sub(r'https?:\\/\\/.*?[\\s+]', '', x.replace(\"|\",\" \") + \" \"))\n",
    "    \n",
    "    #Keep the End Of Sentence characters\n",
    "    df[\"posts\"] = df[\"posts\"].apply(lambda x: re.sub(r'\\.', ' EOSTokenDot ', x + \" \"))\n",
    "    df[\"posts\"] = df[\"posts\"].apply(lambda x: re.sub(r'\\?', ' EOSTokenQuest ', x + \" \"))\n",
    "    df[\"posts\"] = df[\"posts\"].apply(lambda x: re.sub(r'!', ' EOSTokenExs ', x + \" \"))\n",
    "    \n",
    "    #Strip Punctation\n",
    "    df[\"posts\"] = df[\"posts\"].apply(lambda x: re.sub(r'[\\.+]', \".\",x))\n",
    "\n",
    "    #Remove multiple fullstops\n",
    "    df[\"posts\"] = df[\"posts\"].apply(lambda x: re.sub(r'[^\\w\\s]','',x))\n",
    "\n",
    "    #Remove Non-words\n",
    "    df[\"posts\"] = df[\"posts\"].apply(lambda x: re.sub(r'[^a-zA-Z\\s]','',x))\n",
    "\n",
    "    #Convert posts to lowercase\n",
    "    df[\"posts\"] = df[\"posts\"].apply(lambda x: x.lower())\n",
    "\n",
    "    #Remove multiple letter repeating words\n",
    "    df[\"posts\"] = df[\"posts\"].apply(lambda x: re.sub(r'([a-z])\\1{2,}[\\s|\\w]*','',x)) \n",
    "\n",
    "    #Remove very short or long words\n",
    "    df[\"posts\"] = df[\"posts\"].apply(lambda x: re.sub(r'(\\b\\w{0,3})?\\b','',x)) \n",
    "    df[\"posts\"] = df[\"posts\"].apply(lambda x: re.sub(r'(\\b\\w{30,1000})?\\b','',x))\n",
    "\n",
    "    #Remove MBTI Personality Words - crutial in order to get valid model accuracy estimation for unseen data. \n",
    "    if remove_special:\n",
    "        pers_types = ['INFP','INFJ','INTP','INTJ','ENTP','ENFP','ISTP','ISFP',\n",
    "                  'ENTJ','ISTJ','ENFJ','ISFJ','ESTP','ESFP','ESFJ','ESTJ']\n",
    "        # build case-insensitive pattern that matches whole words\n",
    "        p = re.compile(r'\\b(' + \"|\".join([t.lower() for t in pers_types]) + r')\\b')\n",
    "        # actually remove them from posts\n",
    "        df[\"posts\"] = df[\"posts\"].apply(lambda x: p.sub(\"\", x))\n",
    "    return df\n",
    "\n",
    "#Preprocessing of entered Text\n",
    "new_df = preprocess_text(data_set, remove_special=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "edee33a8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>type</th>\n",
       "      <th>posts</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>INFJ</td>\n",
       "      <td>moments   sportscenter    plays   prank...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ENTP</td>\n",
       "      <td>finding  lack    these posts very alarming eo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>INTP</td>\n",
       "      <td>good         course  which    know thats  bles...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>INTJ</td>\n",
       "      <td>dear     enjoyed  conversation  other  eostoke...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ENTJ</td>\n",
       "      <td>youre fired eostokendot    thats another silly...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   type                                              posts\n",
       "0  INFJ         moments   sportscenter    plays   prank...\n",
       "1  ENTP   finding  lack    these posts very alarming eo...\n",
       "2  INTP  good         course  which    know thats  bles...\n",
       "3  INTJ  dear     enjoyed  conversation  other  eostoke...\n",
       "4  ENTJ  youre fired eostokendot    thats another silly..."
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f230d283",
   "metadata": {},
   "source": [
    "### Filtering Short Messages\n",
    "\n",
    "To improve the quality of the text data, we focus only on posts that contain enough words to be informative for the model. \n",
    "\n",
    "Very short messages often lack context and provide little meaningful information about the user's personality. \n",
    "\n",
    "By setting a minimum word threshold, we remove posts that are too brief, ensuring that the dataset contains samples rich enough in content to help the model learn useful patterns. This step helps reduce noise and improves the overall reliability of the model's predictions.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f908d0cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before : Number of posts 8675\n",
      "After : Number of posts 8462\n"
     ]
    }
   ],
   "source": [
    "#Remove posts with less than X words\n",
    "min_words = 15\n",
    "print(\"Before : Number of posts\", len(new_df)) \n",
    "new_df[\"no. of. words\"] = new_df[\"posts\"].apply(lambda x: len(re.findall(r'\\w+', x)))\n",
    "new_df = new_df[new_df[\"no. of. words\"] >= min_words]\n",
    "\n",
    "print(\"After : Number of posts\", len(new_df))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "785aeaf9",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mbti_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
