{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4bdae0fd",
   "metadata": {},
   "source": [
    "We use the [MBTI Kaggle Dataset](https://www.kaggle.com/datasnaek/mbti-type)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5d4e479",
   "metadata": {},
   "source": [
    "## Importing Required Libraries\n",
    "In this section, we import the key Python libraries used for data loading, preprocessing, modeling, and visualization.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "23c2a06b-305f-42f7-8019-6737311cdfd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5194eed",
   "metadata": {},
   "source": [
    "## Dataset Loading and Exploration\n",
    "\n",
    "We begin by loading the MBTI dataset and exploring its structure — including sample entries, class distribution, and basic statistics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "953b8ba7-ca31-4b7b-8ab4-47bf19917c43",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>type</th>\n",
       "      <th>posts</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>INFJ</td>\n",
       "      <td>'http://www.youtube.com/watch?v=qsXHcwe3krw|||...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ENTP</td>\n",
       "      <td>'I'm finding the lack of me in these posts ver...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>INTP</td>\n",
       "      <td>'Good one  _____   https://www.youtube.com/wat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>INTJ</td>\n",
       "      <td>'Dear INTP,   I enjoyed our conversation the o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ENTJ</td>\n",
       "      <td>'You're fired.|||That's another silly misconce...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   type                                              posts\n",
       "0  INFJ  'http://www.youtube.com/watch?v=qsXHcwe3krw|||...\n",
       "1  ENTP  'I'm finding the lack of me in these posts ver...\n",
       "2  INTP  'Good one  _____   https://www.youtube.com/wat...\n",
       "3  INTJ  'Dear INTP,   I enjoyed our conversation the o...\n",
       "4  ENTJ  'You're fired.|||That's another silly misconce..."
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_set = pd.read_csv('../mbti_1.csv') \n",
    "data_set.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45f33b08",
   "metadata": {},
   "source": [
    "## Data Preprocessing\n",
    "\n",
    "Here, we perform minimal text preprocessing to clean and prepare the posts for modeling.  \n",
    "The focus is not on heavy preprocessing but ensuring the text is in a usable form (e.g., lowercasing, removing URLs, punctuation, etc.)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "1d305447",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_text(df, remove_special=True):\n",
    "    texts = df['posts'].copy()\n",
    "    labels = df['type'].copy()\n",
    "\n",
    "    #Remove links \n",
    "    df[\"posts\"] = df[\"posts\"].apply(lambda x: re.sub(r'https?:\\/\\/.*?[\\s+]', '', x.replace(\"|\",\" \") + \" \"))\n",
    "    \n",
    "    #Keep the End Of Sentence characters\n",
    "    df[\"posts\"] = df[\"posts\"].apply(lambda x: re.sub(r'\\.', ' EOSTokenDot ', x + \" \"))\n",
    "    df[\"posts\"] = df[\"posts\"].apply(lambda x: re.sub(r'\\?', ' EOSTokenQuest ', x + \" \"))\n",
    "    df[\"posts\"] = df[\"posts\"].apply(lambda x: re.sub(r'!', ' EOSTokenExs ', x + \" \"))\n",
    "    \n",
    "    #Strip Punctation\n",
    "    df[\"posts\"] = df[\"posts\"].apply(lambda x: re.sub(r'[\\.+]', \".\",x))\n",
    "\n",
    "    #Remove multiple fullstops\n",
    "    df[\"posts\"] = df[\"posts\"].apply(lambda x: re.sub(r'[^\\w\\s]','',x))\n",
    "\n",
    "    #Remove Non-words\n",
    "    df[\"posts\"] = df[\"posts\"].apply(lambda x: re.sub(r'[^a-zA-Z\\s]','',x))\n",
    "\n",
    "    #Convert posts to lowercase\n",
    "    df[\"posts\"] = df[\"posts\"].apply(lambda x: x.lower())\n",
    "\n",
    "    #Remove multiple letter repeating words\n",
    "    df[\"posts\"] = df[\"posts\"].apply(lambda x: re.sub(r'([a-z])\\1{2,}[\\s|\\w]*','',x)) \n",
    "\n",
    "    #Remove very short or long words\n",
    "    df[\"posts\"] = df[\"posts\"].apply(lambda x: re.sub(r'(\\b\\w{0,3})?\\b','',x)) \n",
    "    df[\"posts\"] = df[\"posts\"].apply(lambda x: re.sub(r'(\\b\\w{30,1000})?\\b','',x))\n",
    "\n",
    "    #Remove MBTI Personality Words - crutial in order to get valid model accuracy estimation for unseen data. \n",
    "    if remove_special:\n",
    "        pers_types = ['INFP','INFJ','INTP','INTJ','ENTP','ENFP','ISTP','ISFP',\n",
    "                  'ENTJ','ISTJ','ENFJ','ISFJ','ESTP','ESFP','ESFJ','ESTJ']\n",
    "        # build case-insensitive pattern that matches whole words\n",
    "        p = re.compile(r'\\b(' + \"|\".join([t.lower() for t in pers_types]) + r')\\b')\n",
    "        # actually remove them from posts\n",
    "        df[\"posts\"] = df[\"posts\"].apply(lambda x: p.sub(\"\", x))\n",
    "    return df\n",
    "\n",
    "#Preprocessing of entered Text\n",
    "new_df = preprocess_text(data_set, remove_special=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "edee33a8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>type</th>\n",
       "      <th>posts</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>INFJ</td>\n",
       "      <td>moments   sportscenter    plays   prank...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ENTP</td>\n",
       "      <td>finding  lack    these posts very alarming eo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>INTP</td>\n",
       "      <td>good         course  which    know thats  bles...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>INTJ</td>\n",
       "      <td>dear     enjoyed  conversation  other  eostoke...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ENTJ</td>\n",
       "      <td>youre fired eostokendot    thats another silly...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   type                                              posts\n",
       "0  INFJ         moments   sportscenter    plays   prank...\n",
       "1  ENTP   finding  lack    these posts very alarming eo...\n",
       "2  INTP  good         course  which    know thats  bles...\n",
       "3  INTJ  dear     enjoyed  conversation  other  eostoke...\n",
       "4  ENTJ  youre fired eostokendot    thats another silly..."
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f230d283",
   "metadata": {},
   "source": [
    "### Filtering Short Messages\n",
    "\n",
    "To improve the quality of the text data, we focus only on posts that contain enough words to be informative for the model. \n",
    "\n",
    "Very short messages often lack context and provide little meaningful information about the user's personality. \n",
    "\n",
    "By setting a minimum word threshold, we remove posts that are too brief, ensuring that the dataset contains samples rich enough in content to help the model learn useful patterns. This step helps reduce noise and improves the overall reliability of the model's predictions.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "f908d0cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before : Number of posts 8675\n",
      "After : Number of posts 8462\n"
     ]
    }
   ],
   "source": [
    "# Remove posts with less than min_words\n",
    "import re\n",
    "\n",
    "min_words = 15\n",
    "print(\"Before : Number of posts\", len(new_df)) \n",
    "\n",
    "# Count words\n",
    "new_df[\"no. of. words\"] = new_df[\"posts\"].apply(lambda x: len(re.findall(r'\\w+', x)))\n",
    "\n",
    "# Filter posts and make a copy\n",
    "new_df = new_df[new_df[\"no. of. words\"] >= min_words].copy()\n",
    "\n",
    "print(\"After : Number of posts\", len(new_df))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "c8f5e82f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>type</th>\n",
       "      <th>posts</th>\n",
       "      <th>no. of. words</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>INFJ</td>\n",
       "      <td>moments   sportscenter    plays   prank...</td>\n",
       "      <td>422</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ENTP</td>\n",
       "      <td>finding  lack    these posts very alarming eo...</td>\n",
       "      <td>793</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>INTP</td>\n",
       "      <td>good         course  which    know thats  bles...</td>\n",
       "      <td>252</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>INTJ</td>\n",
       "      <td>dear     enjoyed  conversation  other  eostoke...</td>\n",
       "      <td>766</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ENTJ</td>\n",
       "      <td>youre fired eostokendot    thats another silly...</td>\n",
       "      <td>399</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   type                                              posts  no. of. words\n",
       "0  INFJ         moments   sportscenter    plays   prank...            422\n",
       "1  ENTP   finding  lack    these posts very alarming eo...            793\n",
       "2  INTP  good         course  which    know thats  bles...            252\n",
       "3  INTJ  dear     enjoyed  conversation  other  eostoke...            766\n",
       "4  ENTJ  youre fired eostokendot    thats another silly...            399"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "785aeaf9",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0ce07d51",
   "metadata": {},
   "source": [
    "## Feature Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6f996e3",
   "metadata": {},
   "source": [
    "### What is it?\n",
    "\n",
    "Feature engineering refers to the process of transforming raw data into meaningful numerical representations that can be used by machine learning models.\n",
    "Most algorithms cannot directly interpret raw text, images, or categorical labels, so this step is essential.\n",
    "\n",
    "In text-based machine learning tasks, feature engineering typically includes:\n",
    "* Cleaning and preprocessing the text (lowercasing, removing stopwords, etc.)\n",
    "* Converting text into numerical vectors (for example using TF-IDF, Bag-of-Words, or embeddings)\n",
    "* Extracting additional features such as sentiment scores or text length\n",
    "* Selecting or reducing the number of features to improve model performance\n",
    "\n",
    "The preprocessing has already been done in the previous section, now comes the part where we make the input features (X) and the target variables (Y) readable for the computer, i.e. \n",
    "* label encoding for the target classes \n",
    "* tokenization for the input features \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b242b14",
   "metadata": {},
   "source": [
    "### Target Variable (Y)\n",
    "\n",
    "The target variable in this project is the MBTI personality type, which can take one of sixteen categorical values. Because this is a multiclass classification task, the target is represented using __*label encoding*__, where each MBTI type is mapped to an integer from 0 to 15. This keeps Y as a single, compact column and aligns with how common machine learning classifiers interpret labels internally—as class indices rather than as numerical values.\n",
    "\n",
    "__*One-hot encoding*__, in contrast, expands a categorical variable into one binary column per category. This is valuable for input features (X), where preventing the model from assuming an ordinal relationship between categories is important. However, using one-hot encoding for the target variable would unnecessarily expand Y into sixteen separate columns. \n",
    "\n",
    "This expansion contributes nothing to learning and __only increases dimensionality__, which is undesirable. Importantly, __*the curse of dimensionality applies to the feature space (X), not the target labels.*__ The model learns from X, so excessively high-dimensional input features can harm performance. Y does not participate in the feature space, so how Y is encoded has no impact on this issue. For these reasons, label encoding is the correct and efficient choice for representing the MBTI target.\n",
    "\n",
    "#### TLDR\n",
    "\n",
    "The curse of dimensionality affects X, not Y. Use label encoding for the MBTI target to keep Y simple as class indices; use one-hot encoding only for categorical input features where dimensionality is justified.\n",
    "\n",
    "This was incorrectly stated in the kaggle code source...\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7999db80",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "e544fed0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Initialize the encoder\n",
    "enc = LabelEncoder()\n",
    "\n",
    "# Fit the encoder on the MBTI types and transform them into integer labels\n",
    "new_df['type_encoded'] = enc.fit_transform(new_df['type'])\n",
    "\n",
    "# Define the target variable\n",
    "target = new_df['type_encoded']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "1f4d8eff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>type</th>\n",
       "      <th>posts</th>\n",
       "      <th>no. of. words</th>\n",
       "      <th>type_encoded</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>INFJ</td>\n",
       "      <td>moments   sportscenter    plays   prank...</td>\n",
       "      <td>422</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ENTP</td>\n",
       "      <td>finding  lack    these posts very alarming eo...</td>\n",
       "      <td>793</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>INTP</td>\n",
       "      <td>good         course  which    know thats  bles...</td>\n",
       "      <td>252</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>INTJ</td>\n",
       "      <td>dear     enjoyed  conversation  other  eostoke...</td>\n",
       "      <td>766</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ENTJ</td>\n",
       "      <td>youre fired eostokendot    thats another silly...</td>\n",
       "      <td>399</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>INTJ</td>\n",
       "      <td>eostokendot    science    perfect eostokendo...</td>\n",
       "      <td>239</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>INFJ</td>\n",
       "      <td>cant draw    nails haha eostokendot  those w...</td>\n",
       "      <td>964</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>INTJ</td>\n",
       "      <td>tend  build   collection  things   desktop th...</td>\n",
       "      <td>139</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>INFJ</td>\n",
       "      <td>sure thats  good question eostokendot   dist...</td>\n",
       "      <td>522</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>INTP</td>\n",
       "      <td>this position where  have  actually     pe...</td>\n",
       "      <td>130</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>INFJ</td>\n",
       "      <td>time  parents were fighting over  dads affair...</td>\n",
       "      <td>1060</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>ENFJ</td>\n",
       "      <td>went through  break  some months  eosto...</td>\n",
       "      <td>325</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>INFJ</td>\n",
       "      <td>santagato         eostokenquest       sure   ...</td>\n",
       "      <td>526</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>INTJ</td>\n",
       "      <td>fair enough  thats   want  look   eostokendot ...</td>\n",
       "      <td>1092</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>INTP</td>\n",
       "      <td>basically this eostokendot  eostokendot  eosto...</td>\n",
       "      <td>633</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    type                                              posts  no. of. words  \\\n",
       "0   INFJ         moments   sportscenter    plays   prank...            422   \n",
       "1   ENTP   finding  lack    these posts very alarming eo...            793   \n",
       "2   INTP  good         course  which    know thats  bles...            252   \n",
       "3   INTJ  dear     enjoyed  conversation  other  eostoke...            766   \n",
       "4   ENTJ  youre fired eostokendot    thats another silly...            399   \n",
       "5   INTJ    eostokendot    science    perfect eostokendo...            239   \n",
       "6   INFJ    cant draw    nails haha eostokendot  those w...            964   \n",
       "7   INTJ   tend  build   collection  things   desktop th...            139   \n",
       "8   INFJ    sure thats  good question eostokendot   dist...            522   \n",
       "9   INTP      this position where  have  actually     pe...            130   \n",
       "10  INFJ   time  parents were fighting over  dads affair...           1060   \n",
       "11  ENFJ         went through  break  some months  eosto...            325   \n",
       "12  INFJ   santagato         eostokenquest       sure   ...            526   \n",
       "13  INTJ  fair enough  thats   want  look   eostokendot ...           1092   \n",
       "14  INTP  basically this eostokendot  eostokendot  eosto...            633   \n",
       "\n",
       "    type_encoded  \n",
       "0              8  \n",
       "1              3  \n",
       "2             11  \n",
       "3             10  \n",
       "4              2  \n",
       "5             10  \n",
       "6              8  \n",
       "7             10  \n",
       "8              8  \n",
       "9             11  \n",
       "10             8  \n",
       "11             0  \n",
       "12             8  \n",
       "13            10  \n",
       "14            11  "
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_df.head(15)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf33d4a8",
   "metadata": {},
   "source": [
    "### Input Features (X)\n",
    "\n",
    "#### Text preprocessing and Vectorization\n",
    "\n",
    "Before we can feed text data into a machine learning model, we need to convert it into a numerical form. A few steps are important here:\n",
    "\n",
    "1. Removing Stop Words: \\\n",
    "Stop words are very common words in English like “the”, “and”, or “is” that appear frequently but carry little meaning. Removing them helps the model focus on words that are more informative. Libraries like NLTK provide a standard list of English stop words.\n",
    "\n",
    "2. Converting Text to Numbers with CountVectorizer: \\\n",
    "CountVectorizer transforms a collection of text documents into a numerical representation. It counts how often each word appears in each document and builds a vocabulary of all words in the dataset. Using stop_words='english' ensures that common words are ignored. This step is crucial because machine learning models cannot process raw text—they need numeric input.\n",
    "\n",
    "3. Resulting Features: \\\n",
    "After vectorization, each post is represented as a high-dimensional vector where each dimension corresponds to a word in the vocabulary. For example, our dataset has 8,466 posts and 98,555 unique words (features). Each row represents a post, and each column indicates how many times a particular word appears in that post."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89d93c15",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "240a7a93",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vectorizing the posts for the model and filtering Stop-words\n",
    "vect = CountVectorizer(stop_words='english') \n",
    "\n",
    "# Converting posts (or training or X feature) into numerical form by count vectorization\n",
    "train =  vect.fit_transform(new_df[\"posts\"])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mbti_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
